# ğŸ” Prompt Refinement using DDPG and SentenceTransformer

This project implements a Deep Deterministic Policy Gradient (DDPG) reinforcement learning agent that refines user prompts to maximize the quality of responses generated by a large language model (LLM) such as Groq API or ChatGPT. The agent uses SentenceTransformer embeddings to measure improvements and is accessible via a Flask-based REST API.

---

## ğŸ“ Project Structure

```
DDPG/
â”œâ”€â”€ app.py               # Flask API server to receive prompts and return refined responses
â”œâ”€â”€ inference_test.py    # Command-line interface for testing prompt refinement
â”œâ”€â”€ main.py              # Trains the DDPG agent on prompt-reward interaction
â”œâ”€â”€ model.py             # Actor, Critic, ReplayBuffer, and DDPGAgent definitions
â”œâ”€â”€ utils.py             # PromptEnvironment with reward function
â”œâ”€â”€ test_ddpg.py         # Unit test for DDPG inference
â”œâ”€â”€ test_env.py          # Unit test for the environment and reward
â”œâ”€â”€ saved_model/         # Trained model weights saved here
â”œâ”€â”€ requirements.txt     # Required Python packages
â””â”€â”€ README.md            # Project documentation (this file)
```

---

## âš™ï¸ Setup Instructions

### 1. ğŸ Create and activate a virtual environment

```bash
python -m venv venv
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate
```

### 2. ğŸ“¦ Install dependencies

```bash
pip install -r requirements.txt
```

---

## Configure Groq API

GROQ_API_KEY=key
GROQ_API_BASE=https://api.groq.com/openai/v1


## ğŸ§  Train the DDPG Agent

Run the following command to train the DDPG agent using prompt refinements and sentiment-based rewards:

```bash
python main.py
```

- After training, the model is saved to:

```
saved_model/ddpg_actor.pth
```

---

## ğŸ¤– Command-line Inference

Use the trained model to refine prompts interactively:

```bash
python inference_test.py
```

Example:

```
ğŸ” Enter your prompt: Give me code for GRU
âœ¨ Refined Prompt: Please provide code for GRU neural network.
ğŸ’¬ LLM Response: <response from Groq or OpenAI>
```

---

## ğŸŒ Run the Flask API

Serve the refined prompt generator as a REST API:

```bash
python app.py
```

It runs at: [http://127.0.0.1:5000/refine](http://127.0.0.1:5000/refine)

### Example cURL usage:

```bash
curl -X POST http://127.0.0.1:5000/refine \
     -H "Content-Type: application/json" \
     -d "{\"prompt\": \"Give me code for GRU\"}"
```

---

## ğŸ§¾ Reward Function

The reward is computed as a weighted sum of:

- âœ… **Cosine Similarity** between original and refined prompt embeddings
- âœ… **Sentiment Consistency** using VADER sentiment analysis

---

## ğŸ“¦ Example Output

```
Original Prompt: give code for GRU
Refined Prompt: Please provide implementation of GRU using Keras.
LLM Response: Here is an example GRU model in Keras...
Reward: 46.72
```

---

## ğŸ§ª Run Unit Tests

```bash
python test_ddpg.py
python test_env.py
```

---

## ğŸ“‹ Requirements

```txt
torch
transformers
sentence-transformers
Flask
nltk
scikit-learn
```




